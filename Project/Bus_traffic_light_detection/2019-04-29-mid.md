YOLO Training의 Resizing 과정에서 그래픽 메모리가 기존 이미지 데이터(해상도 1920\*1080)를 넣었을 때 메모리 초과 오류가 나서 교수님이 제시해주신 방법으로 시도해봤습니다.

사진에서 신호등의 대부분이 사진의 높이 60% 부분에 있기 때문에 사진을 1080 * 60% 정도가 되는 640 픽셀을 기준으로 잡았습니다. 그리고 640 * 640으로 이미지를 3개로 나눴습니다.

![Image](https://i.imgur.com/1IASKBE.png)

그리고 이미지 700장 정도를 3장으로 나눠 총 2100장 정도의 이미지를 아래 Class를 기준으로 Bounding Box를 그렸습니다.
- Class
  - 0 : General TL
  - 1 : Bus-only TL
  - 2 : TL with Sign

 주말에 약 1000장 정도의 Bus TL이 들어간 사진을 확보했습니다. 그리고 Bus TL과 General TL이 들어간 이미지 1200장과 General TL만 들어간 사진 900여 장을 학습시켰습니다. Class는 지난주와 다르게 Sign을 빼고 Bus TL, General TL로만 구분해서 Training 했습니다. 6000번을 Training 시킨 후 동영상을 입력 시켜본 결과 아래와 같이 나왔습니다.

![Image](https://i.imgur.com/5nCgSsY.png)

![Image](https://i.imgur.com/rxyrOQ3.png)

잘 구분하는것처럼 보이지만, 아래와 같이 False Positive의 결과가 많았습니다.

![Image](https://i.imgur.com/oDEiCeN.png)

그래서 자료를 찾아보다가 TL의 arrow를 검출하는 연구에 대한 글을 읽었습니다. 그 글을 읽고, TL의 전체를 Box 처리하는것 보다 신호 자체의 모양을 Box 처리해야 보다 정확한 구분이 가능할것이라는 생각이 들어서 다시 모든 이미지에 대해 Bounding Box를 다시 그린후 Training 시킬 계획입니다.

지난주의 계획대로 TL 전체가 아닌, Light 자체를 검출하는 모델을 만들어봤습니다.

Training dataset은 지난주에 사용했던 이미지들을(2088\*1080) 두장으로 나누어(1080\*1080) 2134개의 이미지를 썼습니다.

6천번 Training한 모델에 Test Video를 입력한 결과 아래 예시 이미지와 같이 나왔습니다.

![Image](https://i.imgur.com/S4EzXJE.png)

![Image](https://i.imgur.com/30520gd.png)

![Image](https://i.imgur.com/1wA3Ue7.png)

정확도를 측정하니 아래와 같이 나왔습니다.

class_id = 0, name = G,          ap = 90.44 %
class_id = 1, name = Bus,        ap = 99.15 %

 for thresh = 0.25, precision = 0.94, recall = 0.99, F1-score = 0.96
 for thresh = 0.25, TP = 665, FP = 43, FN = 6

 mean average precision (mAP@0.50) = 0.947937, or 94.79 

 
위까지의 내용이 이전 주에 했던 내용입니다.

처음에는 신호등 전체를 구분하려고 했으나 Detection을 할 때 bus shape와 일반 TL의 원 모양 shape를 인식하지 못해서 Light의 shape만 인식시키게끔 모델을 바꿨습니다. Accuracy는 향상되었기 때문에 이 방법대로 Detection할 예정입니다.

앞으로 해결해야할 과제는 일반 신호등의 모양에 위에 "버스 전용" 혹은 "중앙 차로 전용"이라고 적힌 표지판을 인식해내야하는데, Real-time Image들에서 보이는 표지판들의 문구가 뚜렷하지 않아서 Detection을 제대로 하지 못해서 다른 방법을 찾아봐야 할 것 같습니다. 각 표지판들에 대해서 학습을 해서 그 신호등만을 골라 낼지 아니면 OCR 모델을 잘 개발해야 할 것 같습니다.